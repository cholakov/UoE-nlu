Training model for 20 epochs
training set: 25000 sentences (batch size 100)
Optimizing loss on 1000 sentences
Vocab size: 2000
Hidden units: 75
Steps for back propagation: 2
Initial learning rate set to 1.5, annealing set to 5
calculating initial mean loss on dev set: 10.866100445506362
calculating initial acc on dev set: 0.0
epoch 1, learning rate 1.5000	epoch done in 77.17 seconds	new loss: 0.8383244503140014	new acc: 0.717
epoch 2, learning rate 1.2500	epoch done in 75.84 seconds	new loss: 0.49486246419812296	new acc: 0.749
epoch 3, learning rate 1.0714	epoch done in 74.65 seconds	new loss: 0.40378818544569023	new acc: 0.791
epoch 4, learning rate 0.9375	epoch done in 79.65 seconds	new loss: 0.3366944654257544	new acc: 0.822
epoch 5, learning rate 0.8333	epoch done in 79.93 seconds	new loss: 0.3371483253707253	new acc: 0.827
epoch 6, learning rate 0.7500	epoch done in 86.57 seconds	new loss: 0.27794822954041887	new acc: 0.851
epoch 7, learning rate 0.6818	epoch done in 78.72 seconds	new loss: 0.3678019026282291	new acc: 0.8
epoch 8, learning rate 0.6250	epoch done in 75.93 seconds	new loss: 0.2398670978508597	new acc: 0.875
