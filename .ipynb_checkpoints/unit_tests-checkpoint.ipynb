{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will test the implementation of predict, acc_deltas, and acc_deltas_bptt in rnn.py, for a simple 3x2 RNN\n",
    "y_exp = np.array([[ 0.39411072,  0.32179748,  0.2840918 ], [ 0.4075143,   0.32013043,  0.27235527], [ 0.41091755,  0.31606385,  0.2730186 ], [ 0.41098376,  0.31825833,  0.27075792], [ 0.41118931,  0.31812307,  0.27068762], [ 0.41356637,  0.31280332,  0.27363031], [ 0.41157736,  0.31584609,  0.27257655]])\n",
    "s_exp = np.array([[ 0.66818777,  0.64565631], [ 0.80500806,  0.80655686], [ 0.85442692,  0.79322425], [ 0.84599959,  0.8270955 ], [ 0.84852462,  0.82794442], [ 0.89340731,  0.7811953 ], [ 0.86164528,  0.79916155], [ 0., 0.]])\n",
    "U_exp = np.array([[ 0.89990596,  0.79983619], [ 0.5000714,   0.30009787]])\n",
    "V_exp = np.array([[ 0.69787081,  0.30129314,  0.39888647], [ 0.60201076,  0.89866058,  0.70149262]])\n",
    "W_exp = np.array([[ 0.57779081,  0.47890397], [ 0.22552931,  0.62294835], [ 0.39667988 , 0.19814768]])\n",
    "\n",
    "loss_expected = 8.19118156763\n",
    "loss2_expected = 3.29724981191\n",
    "loss3_expected = 6.01420605985\n",
    "mean_loss_expected = 1.16684249596\n",
    "np_loss_expected = 0.887758278817\n",
    "\n",
    "acc_expected = 1\n",
    "acc1_np_lm_expected = 0\n",
    "acc2_np_lm_expected = 1\n",
    "\n",
    "# standard BP\n",
    "deltaU_1_exp = np.array([[-0.11298744, -0.107331  ], [ 0.07341862, 0.06939134]])\n",
    "deltaV_1_exp = np.array([[-0.06851441, -0.05931481, -0.05336094], [ 0.06079254,  0.0035937,   0.04875759]])\n",
    "deltaW_1_exp = np.array([[-2.36320453, -2.24145091], [ 3.13861959,  2.93420307], [-0.77541506, -0.69275216]])\n",
    "\n",
    "# BPPT\n",
    "deltaU_3_exp = np.array([[-0.12007034, -0.1141893 ], [ 0.06377434, 0.06003115]])\n",
    "deltaV_3_exp = np.array([[-0.07524721, -0.06495432, -0.05560471], [ 0.05465826, -0.00306904, 0.04567927]])\n",
    "deltaW_3_exp = np.array([[-2.36320453, -2.24145091], [ 3.13861959,  2.93420307], [-0.77541506, -0.69275216]])\n",
    "\n",
    "# binary prediction BP\n",
    "deltaU_1_exp_np = np.array([[0.01926192, 0.01684262], [0.00719671, 0.0062928]])\n",
    "deltaV_1_exp_np = np.array([[0., 0., 0.02156006], [0., 0., 0.00805535]])\n",
    "deltaW_1_exp_np = np.array([[0.50701159, 0.47024475], [-0.27214729, -0.25241205], [-0.23486429, -0.2178327 ]])\n",
    "\n",
    "# binary prediction BPPT\n",
    "deltaU_3_exp_np = np.array([[ 0.0216261, 0.01914693], [0.01044642, 0.00946145]])\n",
    "deltaV_3_exp_np = np.array([[ 0.00223142, 0.00055566, 0.02156006], [0.00336126, 0.00046926, 0.00805535]])\n",
    "deltaW_3_exp_np = np.array([[ 0.50701159, 0.47024475], [-0.27214729, -0.25241205], [-0.23486429, -0.2178327]])\n",
    "\n",
    "vocabsize = 3\n",
    "hdim = 2\n",
    "# RNN with vocab size 3 and 2 hidden layers\n",
    "# Note that, for the binary prediction output vocab size should be 2 \n",
    "# for test case simplicity, here we will use the same input and vocab size\n",
    "# r = RNN(vocabsize,hdim,vocabsize)\n",
    "# r.V[0][0]=0.7\n",
    "# r.V[0][1]=0.3\n",
    "# r.V[0][2]=0.4\n",
    "# r.V[1][0]=0.6\n",
    "# r.V[1][1]=0.9\n",
    "# r.V[1][2]=0.7\n",
    "\n",
    "# r.W[0][0]=0.6\n",
    "# r.W[0][1]=0.5\n",
    "# r.W[1][0]=0.2\n",
    "# r.W[1][1]=0.6\n",
    "# r.W[2][0]=0.4\n",
    "# r.W[2][1]=0.2\n",
    "\n",
    "# r.U[0][0]=0.9\n",
    "# r.U[0][1]=0.8\n",
    "# r.U[1][0]=0.5\n",
    "# r.U[1][1]=0.3\n",
    "\n",
    "\n",
    "x = np.array([0,1,2,1,1,0,2])\n",
    "d = np.array([1,2,1,1,1,1,1])\n",
    "d_np = np.array([0])\n",
    "d1_lm_np = np.array([2,0])\n",
    "d2_lm_np = np.array([0,2])\n",
    "x2 = np.array([1,1,0])\n",
    "d2 = np.array([1,0,2])\n",
    "x3 = np.array([1,1,2,1,2])\n",
    "d3 = np.array([1,2,1,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2018)\n",
    "vocabsize = 3\n",
    "hdim = 2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    xt = np.exp(x - max(x))\n",
    "    return xt / sum(xt)\n",
    "\n",
    "x = np.array([0,1,2,1,1,0,2])\n",
    "U = np.random.randn(hdim, hdim)*np.sqrt(0.1)\n",
    "V = np.random.randn(hdim, vocabsize)*np.sqrt(0.1)\n",
    "W = np.random.randn(vocabsize, hdim)*np.sqrt(0.1)\n",
    "\n",
    "s = np.zeros((len(x) + 1, hdim))\n",
    "y = np.zeros((len(x), vocabsize))\n",
    "    \n",
    "\n",
    "for t in range(len(x)):\n",
    "    xt = np.zeros((1, vocabsize))\n",
    "    xt[0][x[t]] = 1\n",
    "    \n",
    "    st = sigmoid(V.dot(xt.T) + np.expand_dims(U.dot(s[t-1, :].T), axis=1))\n",
    "    yt = softmax(W.dot(st))\n",
    "    \n",
    "    s[t, :] = st.T[0]\n",
    "    y[t, :] = yt.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39005626443057195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array([1,2,1,1,1,1,1])\n",
    "\n",
    "d_hot = np.zeros((len(d), vocabsize))\n",
    "d_hot[np.linspace(0,len(d)-1,len(d), dtype=int),d] = 1\n",
    "\n",
    "y_hat = y_exp\n",
    "J = - np.mean(np.multiply(np.log(y_hat), d_hot))\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 1, 1, 0, 2]), array([1, 1, 0]), array([1, 1, 2, 1, 2])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0,1,2,1,1,0,2])\n",
    "d = np.array([1,2,1,1,1,1,1])\n",
    "d_np = np.array([0])\n",
    "d1_lm_np = np.array([2,0])\n",
    "d2_lm_np = np.array([0,2])\n",
    "x2 = np.array([1,1,0])\n",
    "d2 = np.array([1,0,2])\n",
    "x3 = np.array([1,1,2,1,2])\n",
    "d3 = np.array([1,2,1,2,1])\n",
    "[x,x2,x3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09784674, -0.09925557, -0.09418965, -0.09994889, -0.09873118,\n",
       "        -0.09585871, -0.09473502],\n",
       "       [ 0.1901091 , -0.06248936,  0.19284017,  0.18720927,  0.18766211,\n",
       "         0.18940945,  0.19258771],\n",
       "       [-0.18655622,  0.24577146, -0.18677774, -0.18873277, -0.18962574,\n",
       "        -0.19056795, -0.18646685]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_hot = np.zeros((len(d), vocabsize))\n",
    "d_hot[np.linspace(0, len(d) - 1, len(d), dtype=int), d] = 1\n",
    "delta_out = np.multiply((d_hot - y), y)\n",
    "delta_out.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5396252 , 0.5087016 ],\n",
       "       [0.57861031, 0.48580428],\n",
       "       [0.49839792, 0.58264535],\n",
       "       [0.58280159, 0.47135002],\n",
       "       [0.57601111, 0.49691204],\n",
       "       [0.54979712, 0.5560354 ],\n",
       "       [0.50225893, 0.57093109]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0:s.shape[0]-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.37257977, -0.35643236],\n",
       "       [ 0.5806088 ,  0.57547396],\n",
       "       [-0.46920282, -0.47993856]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_out.T.dot(s[0:s.shape[0]-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30779054 -0.26039139  0.56818193]]\n",
      "[[ 0.69038942 -0.25384852 -0.4365409 ]]\n",
      "[[-0.31421519  0.74967557 -0.43546038]]\n",
      "[[-0.31614694  0.75058079 -0.43443385]]\n",
      "[[-0.30690332 -0.26091878  0.5678221 ]]\n",
      "[[-0.31504851  0.75002127 -0.43497276]]\n",
      "[[ 0.68719536 -0.25527382 -0.43192154]]\n"
     ]
    }
   ],
   "source": [
    "for t in reversed(range(len(x))):\n",
    "    d_hot = np.zeros((1, vocabsize))\n",
    "    d_hot[0][x[t]] = 1\n",
    "\n",
    "    delta_out = d_hot - y[t]\n",
    "    print(delta_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5396252 , 0.5087016 ],\n",
       "       [0.57861031, 0.48580428],\n",
       "       [0.49839792, 0.58264535],\n",
       "       [0.58280159, 0.47135002],\n",
       "       [0.57601111, 0.49691204],\n",
       "       [0.54979712, 0.5560354 ],\n",
       "       [0.50225893, 0.57093109],\n",
       "       [0.        , 0.        ]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50225893]\n",
      " [0.57093109]]\n",
      "[[0.54979712]\n",
      " [0.5560354 ]]\n",
      "[[0.57601111]\n",
      " [0.49691204]]\n",
      "[[0.58280159]\n",
      " [0.47135002]]\n",
      "[[0.49839792]\n",
      " [0.58264535]]\n",
      "[[0.57861031]\n",
      " [0.48580428]]\n",
      "[[0.5396252]\n",
      " [0.5087016]]\n"
     ]
    }
   ],
   "source": [
    "for t in reversed(range(len(x))):\n",
    "    print(np.expand_dims(s[t][:], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
