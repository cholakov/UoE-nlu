%%%%%%%% ICML 2018 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{listings}
\usepackage{xcolor}
\usepackage{enumerate}
\usepackage{appendix}
\usepackage{mdframed}
\usepackage{multirow}
\usepackage{bigstrut}
\usepackage{csquotes}
% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2018} with \usepackage[nohyperref]{icml2018} above.
\usepackage{hyperref}

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{F6F6F6}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\renewcommand\lstlistingname{\vspace{1.5mm} Extract}
% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2018}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2018}
\lstset{language=Python,   basicstyle=\tiny\ttfamily, backgroundcolor=\color{black!5!white}, breaklines=true}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Natural Language Understanding - Recurrent Neural Networks Coursework}

\begin{document}

\twocolumn[
\icmltitle{NLU - Recurrent Neural Networks Coursework}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2018
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{G33: Boda, Kristian (S1788211); Cholakov, Vesko (S1753272)}{}
\end{icmlauthorlist}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document

]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution

\section{Question 2. (a)}
Perform parameter tuning using a subset of the training and development sets. Use a fixed vocabulary of size 2000, and vary the number of hidden units (at least: 25, 50), the look-back in backpropagation (at least: 0, 2, 5), and learning rate (at least: 0.5, 0.1, 0.05). The mode train-lm in rnn.py allows for more parameters, which you are free to explore. You should tune your model to maximize generalization performance (minimize cross-entropy loss) on the dev set. For these experiments, use the first 1000 sentences of both the training and development sets and train for 10 epochs.6 Report your findings. [10 marks]

\section{Question 3. (b)}
Train your new model, explaining the parameters you used and how you chose them, and include the results in your report. [5 marks]
Training model for 20 epochs
training set: 25000 sentences (batch size 100)
Optimizing loss on 1000 sentences
Vocab size: 2000
Hidden units: 75
Steps for back propagation: 2
Initial learning rate set to 1.5, annealing set to 5
calculating initial mean loss on dev set: 10.866100445506362
calculating initial acc on dev set: 0.0
epoch 1, learning rate 1.5000	epoch done in 77.17 seconds	new loss: 0.8383244503140014	new acc: 0.717
epoch 2, learning rate 1.2500	epoch done in 75.84 seconds	new loss: 0.49486246419812296	new acc: 0.749
epoch 3, learning rate 1.0714	epoch done in 74.65 seconds	new loss: 0.40378818544569023	new acc: 0.791
epoch 4, learning rate 0.9375	epoch done in 79.65 seconds	new loss: 0.3366944654257544	new acc: 0.822
epoch 5, learning rate 0.8333	epoch done in 79.93 seconds	new loss: 0.3371483253707253	new acc: 0.827
epoch 6, learning rate 0.7500	epoch done in 86.57 seconds	new loss: 0.27794822954041887	new acc: 0.851
epoch 7, learning rate 0.6818	epoch done in 78.72 seconds	new loss: 0.3678019026282291	new acc: 0.8
epoch 8, learning rate 0.6250	epoch done in 75.93 seconds	new loss: 0.2398670978508597	new acc: 0.875

\section{Question 4. (a)}
Implement method compare num pred and evaluate your prediction accuracy: > python rnn.py predict-lm rnn.py data dir rnn dir
Include your result in your final report. [4 marks]

\section{Question 4. (b)}
Knowledge: Comprehensive range of up-to-date material handled in a professional way.
Understanding and handling of key concepts: Shows a command of the subject and current theory.
Focus on the subject: Clear and analytical; fully explores the subject.
Critical analysis and discussion: Shows evidence of serious thought in critically evaluating and integrating the evidenced and ideas. Deals confidently with the complexities and subtleties of the arguments. Shows elements of personal insight / creativity / originality.
Literature synthesised, analysed and referenced: Comprehensive grasp of the up-to-date literature which is used in a professional way.
Structure: Clear and coherent showing logical, ordered thought.
Presentation: Clear and professional with few, relatively minor flaws. Accurate referencing; using the correct referencing system. Figures and tables well constructed and accurate. Good standard of spelling and grammar.
\newpage
\bibliography{library}
\bibliographystyle{icml2018}

\newpage
\appendix

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018. It was modified from a version from Dan Roy in
% 2017, which was based on a version from Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
